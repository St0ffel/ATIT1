{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common / KNN imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy.spatial.distance\n",
    "from collections import Counter\n",
    "plt.set_cmap('gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "# Load MNIST Data\n",
    "#-----------------------------------------------\n",
    "mnist_data = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Get Training set\n",
    "train = mnist_data[0]\n",
    "x_mnist_train_full, y_mnist_train_full = train[0], train[1]\n",
    "\n",
    "# Get Test set\n",
    "test = mnist_data[1]\n",
    "x_mnist_test_full, y_mnist_test_full = test[0], test[1]\n",
    "\n",
    "n_mnist_train = x_mnist_train_full.shape[0]\n",
    "n_mnist_test =x_mnist_test_full.shape[0]\n",
    "\n",
    "m = x_mnist_train_full.shape[1]**2\n",
    "\n",
    "x_mnist_train_full = x_mnist_train_full.reshape([n_train, m])\n",
    "x_mnist_test_full = x_mnist_test_full.reshape([n_test, m])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------\n",
    "# Create MNIST Subset\n",
    "#-----------------------------------------------\n",
    "\n",
    "# Create train subset\n",
    "idx = np.random.randint(n_train, size= 1000)\n",
    "x_mnist_train = x_mnist_train_full[idx]\n",
    "y_mnist_train = y_mnist_train_full[idx]\n",
    "\n",
    "# Create test subset\n",
    "idx = np.random.randint(n_test, size= 30)\n",
    "x_mnist_test = x_mnist_test_full[idx]\n",
    "y_mnist_test = y_mnist_test_full[idx]\n",
    "\n",
    "def set_mnist_subsets(train_size, test_size):\n",
    "    global n_mnist_train\n",
    "    global n_mnist_test\n",
    "    global x_mnist_train\n",
    "    global y_mnist_train\n",
    "    global x_mnist_test\n",
    "    global y_mnist_test\n",
    "    \n",
    "    idx = np.random.randint(n_mnist_train, size= train_size)\n",
    "    x_mnist_train = x_mnist_train_full[idx]\n",
    "    y_mnist_train = y_mnist_train_full[idx]\n",
    "    idx = np.random.randint(n_mnist_test, size= test_size)\n",
    "    x_mnist_test = x_mnist_test_full[idx]\n",
    "    y_mnist_test = y_mnist_test_full[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------\n",
    "# Load CIFAR data\n",
    "#-----------------------------------------------\n",
    "\n",
    "cifar = tf.keras.datasets.cifar10.load_data()[0]\n",
    "x_cifar, y_cifar = cifar[0], cifar[1]\n",
    "\n",
    "# Convert to grayscale\n",
    "x_cifar = np.dot(x_cifar[...,:3], [0.299, 0.587, 0.114])\n",
    "print(x_cifar.shape)\n",
    "\n",
    "n_x_cifar = x_cifar.shape[0]\n",
    "m_x_cifar = x_cifar.shape[1]**2\n",
    "\n",
    "x_cifar = x_cifar.reshape([n_x_cifar, m_x_cifar])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1024)\n",
      "(30,)\n",
      "(1000, 1024)\n",
      "(1000,)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------\n",
    "# Create Cifar Subset\n",
    "#-----------------------------------------------\n",
    "idx = np.random.randint(n_x_cifar, size=1030)\n",
    "x_cifar_sample = x_cifar[idx]\n",
    "y_cifar_sample = y_cifar[idx]\n",
    "\n",
    "# Create test & train set\n",
    "x_cifar_test = x_cifar_sample[:30]\n",
    "y_cifar_test = y_cifar_sample[:30,0]\n",
    "\n",
    "x_cifar_train = x_cifar_sample[30:]\n",
    "y_cifar_train = y_cifar_sample[30:,0]\n",
    "\n",
    "def set_cifar_subsets(train_size, test_size):\n",
    "    global n_x_cifar\n",
    "    global x_cifar_train\n",
    "    global y_cifar_train\n",
    "    global x_cifar_test\n",
    "    global y_cifar_test\n",
    "    \n",
    "    idx = np.random.randint(n_x_cifar, size= train_size + test_size)\n",
    "    x_cifar_sample = x_cifar[idx]\n",
    "    y_cifar_sample = y_cifar[idx]\n",
    "\n",
    "    # Create test & train set\n",
    "    x_cifar_test = x_cifar_sample[:test_size]\n",
    "    y_cifar_test = y_cifar_sample[:test_size,0]\n",
    "\n",
    "    x_cifar_train = x_cifar_sample[test_size:]\n",
    "    y_cifar_train = y_cifar_sample[test_size:,0]\n",
    "\n",
    "\n",
    "print(x_cifar_test.shape)\n",
    "print(y_cifar_test.shape)\n",
    "print(x_cifar_train.shape)\n",
    "print(y_cifar_train.shape)\n",
    "print(y_cifar_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many distances you need to calculate if you have 60,000 samples in the trainingset for 50 samples?\n",
    "Man muss 3.000.000 Abstände berechnen.\n",
    "#### How many distances do you need to calculate if you have n samples im the trainingset?\n",
    "Man muss immer n * 50 Abstände berechnen, d.h. bei 3 Samples müsste man 150 Abstände berechnen, bei 90.000 dann 4.500.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k, x_train, y_train, x_test):\n",
    "    dists = scipy.spatial.distance.cdist(x_train, x_test, metric='euclid')\n",
    "    idx_nearest = np.argpartition(dists, k, axis=0)[:k]\n",
    "    idx_nearest = np.swapaxes(idx_nearest, 0, 1)\n",
    "    #print(idx_nearest)\n",
    "\n",
    "    closest_points_labels = y_train[idx_nearest]\n",
    "    y_test_predictions = []\n",
    "    \n",
    "    for index, predicted_labels in enumerate(closest_points_labels):\n",
    "        y_test_predictions.append(np.bincount(predicted_labels).argmax())\n",
    "    return y_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_print_error_rate(y_test,  y_test_predictions):\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    correct_labels = (y_test)\n",
    "    \n",
    "    numbers_count = Counter(correct_labels)\n",
    "    \n",
    "    numbers_correct = dict.fromkeys(numbers_count.keys(), 0)\n",
    "    \n",
    "    #numbers_error_rate = dict.fromkeys(numbers_count.keys(), None)\n",
    "    \n",
    "    \n",
    "    n = correct_labels.shape[0]\n",
    "    \n",
    "    for index, prediction in enumerate( y_test_predictions):\n",
    "        if prediction == correct_labels[index]:\n",
    "            correct += 1\n",
    "            numbers_correct[prediction] += 1\n",
    "        \n",
    "    error_rate = 1- (correct / n)\n",
    "    \n",
    "    \n",
    "    for key in sorted(numbers_count):\n",
    "        count = numbers_count[key]\n",
    "        correct = numbers_correct[key]\n",
    "        error = 1 - numbers_correct[key] / numbers_count[key]\n",
    "        print(\"Label:\", key)\n",
    "        print(\"  \", correct, \"out of\", count, \"recognized correctly | Errorrate:\", error*100, \"%\")\n",
    "        \n",
    "    print(\"\\n\"+\"Resulting errorrate:\", error_rate*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mnist_subsets(10000,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 7, 3, 8, 9, 8, 0, 8, 1, 7, 5, 6, 9, 6, 7, 2, 4, 7, 1, 4, 8, 5, 4, 0, 6, 2, 1, 8, 4, 0] \n",
      "\n",
      "-------------------------------------\n",
      "  2NN  \n",
      "-------------------------------------\n",
      "Predictions:\n",
      "[2, 7, 3, 8, 9, 8, 0, 5, 1, 0, 5, 6, 9, 6, 7, 2, 4, 1, 1, 4, 8, 5, 4, 0, 6, 2, 1, 8, 4, 0] \n",
      "\n",
      "Label: 0\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 1\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 2\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 3\n",
      "   1 out of 1 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 4\n",
      "   4 out of 4 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 5\n",
      "   2 out of 2 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 6\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 7\n",
      "   2 out of 4 recognized correctly | Errorrate: 50.0 %\n",
      "Label: 8\n",
      "   4 out of 5 recognized correctly | Errorrate: 19.999999999999996 %\n",
      "Label: 9\n",
      "   2 out of 2 recognized correctly | Errorrate: 0.0 %\n",
      "\n",
      "Resulting errorrate: 9.999999999999998 %\n",
      "-------------------------------------\n",
      "  4NN  \n",
      "-------------------------------------\n",
      "Predictions:\n",
      "[2, 7, 3, 8, 9, 8, 0, 5, 1, 9, 5, 6, 9, 6, 7, 2, 4, 1, 1, 4, 8, 5, 4, 0, 6, 2, 1, 8, 4, 0] \n",
      "\n",
      "Label: 0\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 1\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 2\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 3\n",
      "   1 out of 1 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 4\n",
      "   4 out of 4 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 5\n",
      "   2 out of 2 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 6\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 7\n",
      "   2 out of 4 recognized correctly | Errorrate: 50.0 %\n",
      "Label: 8\n",
      "   4 out of 5 recognized correctly | Errorrate: 19.999999999999996 %\n",
      "Label: 9\n",
      "   2 out of 2 recognized correctly | Errorrate: 0.0 %\n",
      "\n",
      "Resulting errorrate: 9.999999999999998 %\n",
      "-------------------------------------\n",
      "  8NN  \n",
      "-------------------------------------\n",
      "Predictions:\n",
      "[2, 7, 3, 8, 9, 8, 0, 8, 1, 9, 5, 6, 9, 6, 7, 2, 4, 1, 1, 4, 8, 5, 4, 0, 6, 2, 1, 8, 4, 0] \n",
      "\n",
      "Label: 0\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 1\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 2\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 3\n",
      "   1 out of 1 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 4\n",
      "   4 out of 4 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 5\n",
      "   2 out of 2 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 6\n",
      "   3 out of 3 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 7\n",
      "   2 out of 4 recognized correctly | Errorrate: 50.0 %\n",
      "Label: 8\n",
      "   5 out of 5 recognized correctly | Errorrate: 0.0 %\n",
      "Label: 9\n",
      "   2 out of 2 recognized correctly | Errorrate: 0.0 %\n",
      "\n",
      "Resulting errorrate: 6.666666666666665 %\n"
     ]
    }
   ],
   "source": [
    "predictions2 = knn(2, x_mnist_train, y_mnist_train, x_mnist_test)\n",
    "predictions4 = knn(4, x_mnist_train, y_mnist_train, x_mnist_test)\n",
    "predictions8 = knn(8, x_mnist_train, y_mnist_train, x_mnist_test)\n",
    "\n",
    "print(list(y_mnist_test), \"\\n\")\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  2NN  \")\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Predictions:\")\n",
    "print(predictions2, \"\\n\")\n",
    "knn_print_error_rate(y_mnist_test, predictions2)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  4NN  \")\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Predictions:\")\n",
    "print(predictions4, \"\\n\")\n",
    "knn_print_error_rate(y_mnist_test, predictions4)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  8NN  \")\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Predictions:\")\n",
    "print(predictions8, \"\\n\")\n",
    "knn_print_error_rate(y_mnist_test,predictions8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the error rate of KNN on the test set?\n",
    "Die Errorrate beim ersten Testen (mit k=2, train = 10.000, test = 30) war 6%.  \n",
    "Beim testen mit neuen subsets gab es auch Errorraten zwischen 3 - 16%\n",
    "##### What is the error rate for each label (number)?\n",
    "Die Errorraten beim ersten Testen (mit k=2) waren:\n",
    "* 0 - 0.0%\n",
    "* 1 - 0.0%\n",
    "* 2 - 0.0%\n",
    "* 3 - 0.0%\n",
    "* 4 - 33.0% (2/3)\n",
    "* 5 - 20.0% (4/5)\n",
    "* 6 - 0.0%\n",
    "* 7 - 0.0%\n",
    "* 8 - 0.0%\n",
    "* 9 - 0.0%  \n",
    "  \n",
    "Beim testen mit anderen Subsets fällt auf, dass es bei den Zahlen 0-2 tendenziell niedrigere Fehlerquoten gibt als beim Rest.\n",
    "##### How does the choice of k influence the result?\n",
    "Beim ersten Testen hat sich die Errorrate mit zunehmendem k verbessert:\n",
    "\n",
    "* k = 2: 6%\n",
    "* k = 4: 3%\n",
    "* k = 8: 3%  \n",
    "  \n",
    "Beim Testen mit anderen Subsets ist aufgefallen, dass k sich nicht immer auf die Errorquote auswirkt, aber k=4 tendenziell niedrigere Errorraten für unsere Test- und Traingrößen hatte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C K-means MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_train(k, it, x_train, y_train):\n",
    "    \n",
    "    # init centroids\n",
    "    idx_centroid = np.random.randint(x_train.shape[0], size=k)\n",
    "    centroids = x_train[idx_centroid]\n",
    "    \n",
    "    # calc distances\n",
    "    dists = scipy.spatial.distance.cdist(x_train, centroids, metric='euclid')\n",
    "    \n",
    "    # find nearest centroids\n",
    "    labels = np.argmin(dists, axis=1)\n",
    "\n",
    "    # train model for q iterations\n",
    "    for j in range(it):\n",
    "        \n",
    "        # calc distances\n",
    "        dists = scipy.spatial.distance.cdist(x_train, centroids, metric='euclid')\n",
    "        \n",
    "        # label according to nearest centroids\n",
    "        labels = np.argmin(dists, axis=1)\n",
    "        \n",
    "        # get new centroids\n",
    "        centroid_list = [x_train[labels == i].mean(0) for i in range(k)]\n",
    "        centroids = np.stack(centroid_list)\n",
    "        \n",
    "        \n",
    "        # print results\n",
    "\n",
    "    for i in range(k):\n",
    "    \n",
    "        size = y_train[labels == i].shape[0]\n",
    "        bincount = np.bincount(y_train[labels == i])\n",
    "        mode = bincount.argmax()\n",
    "        correct = bincount[mode]\n",
    "        percentage = correct / size\n",
    "    \n",
    "        print('group', i)\n",
    "        print(\"-------------------------------------\")\n",
    "        print(\"label\", mode, \"(size:\", size, \")\")\n",
    "        print(\"correct\", correct)\n",
    "        print(\"size\", size)\n",
    "        print(\"Percentage of majority class:\", percentage*100, \"%\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mnist_subsets(1000,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 1000 samples in 0.053s...\n",
      "[t-SNE] Computed neighbors for 1000 samples in 3.217s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1000\n",
      "[t-SNE] Mean sigma: 437.612039\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 68.914360\n",
      "[t-SNE] KL divergence after 300 iterations: 1.315916\n"
     ]
    }
   ],
   "source": [
    "k_mnist = 10\n",
    "itr_means = 30\n",
    "\n",
    "_tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "embedding = _tsne.fit_transform(x_mnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group 0\n",
      "-------------------------------------\n",
      "label 1 (size: 142 )\n",
      "correct 50\n",
      "size 142\n",
      "Percentage of majority class: 35.2112676056338 % \n",
      "\n",
      "group 1\n",
      "-------------------------------------\n",
      "label 2 (size: 64 )\n",
      "correct 60\n",
      "size 64\n",
      "Percentage of majority class: 93.75 % \n",
      "\n",
      "group 2\n",
      "-------------------------------------\n",
      "label 0 (size: 63 )\n",
      "correct 57\n",
      "size 63\n",
      "Percentage of majority class: 90.47619047619048 % \n",
      "\n",
      "group 3\n",
      "-------------------------------------\n",
      "label 6 (size: 90 )\n",
      "correct 76\n",
      "size 90\n",
      "Percentage of majority class: 84.44444444444444 % \n",
      "\n",
      "group 4\n",
      "-------------------------------------\n",
      "label 3 (size: 129 )\n",
      "correct 68\n",
      "size 129\n",
      "Percentage of majority class: 52.71317829457365 % \n",
      "\n",
      "group 5\n",
      "-------------------------------------\n",
      "label 7 (size: 135 )\n",
      "correct 50\n",
      "size 135\n",
      "Percentage of majority class: 37.03703703703704 % \n",
      "\n",
      "group 6\n",
      "-------------------------------------\n",
      "label 0 (size: 50 )\n",
      "correct 39\n",
      "size 50\n",
      "Percentage of majority class: 78.0 % \n",
      "\n",
      "group 7\n",
      "-------------------------------------\n",
      "label 1 (size: 115 )\n",
      "correct 61\n",
      "size 115\n",
      "Percentage of majority class: 53.04347826086957 % \n",
      "\n",
      "group 8\n",
      "-------------------------------------\n",
      "label 4 (size: 118 )\n",
      "correct 42\n",
      "size 118\n",
      "Percentage of majority class: 35.59322033898305 % \n",
      "\n",
      "group 9\n",
      "-------------------------------------\n",
      "label 8 (size: 94 )\n",
      "correct 56\n",
      "size 94\n",
      "Percentage of majority class: 59.57446808510638 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_train(k_mnist, itr_means, x_mnist_train, y_mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do this for 10, 100, 1000 iterations\n",
    "##### What is the majority class of each cluster?\n",
    "##### What is the percentage of the majority class in each cluster?\n",
    "##### Does each number have a cluster?\n",
    "##### If not, which hasn’t?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D MNIST understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some numbers are more difficult to predict with KNN and to cluster with K-means. Show why.  Start with examples, and get more general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E KNN and K-means CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_cifar_subsets(10000,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 0, 5, 3, 9, 6, 2, 5, 8, 9, 5, 1, 9, 6, 8, 6, 6, 3, 6, 9, 4, 3, 1, 9, 8, 4, 0, 2, 0, 9] \n",
      "\n",
      "-------------------------------------\n",
      "  2NN  \n",
      "-------------------------------------\n",
      "Predictions:\n",
      "[5, 8, 0, 5, 8, 6, 3, 1, 3, 1, 0, 5, 6, 1, 6, 7, 3, 2, 6, 9, 5, 0, 1, 4, 9, 3, 0, 1, 2, 2] \n",
      "\n",
      "Label: 0\n",
      "   1 out of 3 recognized correctly | Errorrate: 66.66666666666667 %\n",
      "Label: 1\n",
      "   1 out of 2 recognized correctly | Errorrate: 50.0 %\n",
      "Label: 2\n",
      "   0 out of 2 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 3\n",
      "   0 out of 3 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 4\n",
      "   0 out of 2 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 5\n",
      "   0 out of 3 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 6\n",
      "   2 out of 5 recognized correctly | Errorrate: 60.0 %\n",
      "Label: 8\n",
      "   0 out of 4 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 9\n",
      "   1 out of 6 recognized correctly | Errorrate: 83.33333333333334 %\n",
      "\n",
      "Resulting errorrate: 83.33333333333334 %\n",
      "-------------------------------------\n",
      "  4NN  \n",
      "-------------------------------------\n",
      "Predictions:\n",
      "[5, 8, 0, 4, 8, 1, 3, 1, 6, 1, 0, 5, 6, 1, 6, 7, 3, 2, 6, 9, 5, 0, 1, 4, 9, 3, 0, 1, 2, 2] \n",
      "\n",
      "Label: 0\n",
      "   1 out of 3 recognized correctly | Errorrate: 66.66666666666667 %\n",
      "Label: 1\n",
      "   1 out of 2 recognized correctly | Errorrate: 50.0 %\n",
      "Label: 2\n",
      "   0 out of 2 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 3\n",
      "   0 out of 3 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 4\n",
      "   0 out of 2 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 5\n",
      "   0 out of 3 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 6\n",
      "   1 out of 5 recognized correctly | Errorrate: 80.0 %\n",
      "Label: 8\n",
      "   0 out of 4 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 9\n",
      "   1 out of 6 recognized correctly | Errorrate: 83.33333333333334 %\n",
      "\n",
      "Resulting errorrate: 86.66666666666667 %\n",
      "-------------------------------------\n",
      "  8NN  \n",
      "-------------------------------------\n",
      "Predictions:\n",
      "[5, 8, 0, 4, 8, 6, 3, 1, 6, 1, 0, 5, 6, 1, 6, 7, 3, 2, 6, 9, 5, 0, 1, 4, 9, 3, 0, 1, 1, 2] \n",
      "\n",
      "Label: 0\n",
      "   1 out of 3 recognized correctly | Errorrate: 66.66666666666667 %\n",
      "Label: 1\n",
      "   1 out of 2 recognized correctly | Errorrate: 50.0 %\n",
      "Label: 2\n",
      "   0 out of 2 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 3\n",
      "   0 out of 3 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 4\n",
      "   0 out of 2 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 5\n",
      "   0 out of 3 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 6\n",
      "   2 out of 5 recognized correctly | Errorrate: 60.0 %\n",
      "Label: 8\n",
      "   0 out of 4 recognized correctly | Errorrate: 100.0 %\n",
      "Label: 9\n",
      "   1 out of 6 recognized correctly | Errorrate: 83.33333333333334 %\n",
      "\n",
      "Resulting errorrate: 83.33333333333334 %\n"
     ]
    }
   ],
   "source": [
    "predictions2 = knn(2, x_cifar_train, y_cifar_train, x_cifar_test)\n",
    "predictions4 = knn(4, x_cifar_train, y_cifar_train, x_cifar_test)\n",
    "predictions8 = knn(8, x_cifar_train, y_cifar_train, x_cifar_test)\n",
    "\n",
    "predictions2 = knn(2, x_mnist_train, y_mnist_train, x_mnist_test)\n",
    "predictions4 = knn(4, x_mnist_train, y_mnist_train, x_mnist_test)\n",
    "predictions8 = knn(8, x_mnist_train, y_mnist_train, x_mnist_test)\n",
    "\n",
    "print(list(y_cifar_test), \"\\n\")\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  2NN  \")\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Predictions:\")\n",
    "print(predictions2, \"\\n\")\n",
    "knn_print_error_rate(y_cifar_test, predictions2)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  4NN  \")\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Predictions:\")\n",
    "print(predictions4, \"\\n\")\n",
    "knn_print_error_rate(y_cifar_test, predictions4)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"  8NN  \")\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Predictions:\")\n",
    "print(predictions8, \"\\n\")\n",
    "knn_print_error_rate(y_cifar_test,predictions8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group 0\n",
      "-------------------------------------\n",
      "label 5 (size: 132 )\n",
      "correct 35\n",
      "size 132\n",
      "Percentage of majority class: 26.515151515151516 % \n",
      "\n",
      "group 1\n",
      "-------------------------------------\n",
      "label 8 (size: 97 )\n",
      "correct 21\n",
      "size 97\n",
      "Percentage of majority class: 21.649484536082475 % \n",
      "\n",
      "group 2\n",
      "-------------------------------------\n",
      "label 0 (size: 94 )\n",
      "correct 16\n",
      "size 94\n",
      "Percentage of majority class: 17.02127659574468 % \n",
      "\n",
      "group 3\n",
      "-------------------------------------\n",
      "label 3 (size: 119 )\n",
      "correct 24\n",
      "size 119\n",
      "Percentage of majority class: 20.168067226890756 % \n",
      "\n",
      "group 4\n",
      "-------------------------------------\n",
      "label 6 (size: 82 )\n",
      "correct 17\n",
      "size 82\n",
      "Percentage of majority class: 20.73170731707317 % \n",
      "\n",
      "group 5\n",
      "-------------------------------------\n",
      "label 1 (size: 47 )\n",
      "correct 8\n",
      "size 47\n",
      "Percentage of majority class: 17.02127659574468 % \n",
      "\n",
      "group 6\n",
      "-------------------------------------\n",
      "label 1 (size: 135 )\n",
      "correct 28\n",
      "size 135\n",
      "Percentage of majority class: 20.74074074074074 % \n",
      "\n",
      "group 7\n",
      "-------------------------------------\n",
      "label 9 (size: 80 )\n",
      "correct 29\n",
      "size 80\n",
      "Percentage of majority class: 36.25 % \n",
      "\n",
      "group 8\n",
      "-------------------------------------\n",
      "label 5 (size: 145 )\n",
      "correct 26\n",
      "size 145\n",
      "Percentage of majority class: 17.93103448275862 % \n",
      "\n",
      "group 9\n",
      "-------------------------------------\n",
      "label 8 (size: 69 )\n",
      "correct 19\n",
      "size 69\n",
      "Percentage of majority class: 27.536231884057973 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_cifar_subsets(1000,30)\n",
    "k_cifar = 10\n",
    "itr_means = 30\n",
    "kmeans_train(k_cifar, itr_means, x_cifar_train, y_cifar_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform cifar-10 to grayscale.\n",
    "* Does knn work similarly good?\n",
    "* Does k-means work similarly good?\n",
    "* Demonstrate this similar to B, C and D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F Linear regression BOSTON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a linear regression model on the BOSTON dataset to predict median\n",
    "values of houses. Test it on the test set. Show the code how you did it! What\n",
    "dependent variables (columns) have the biggest influence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G Logistik regression MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalute logistic regression as B and D on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much time did you work on this assignment and how often did you\n",
    "meet?\n",
    "* Did you use Google Colab or Anaconda?\n",
    "* What was your favourite excercise? Why?\n",
    "* What excercise did you like least? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
